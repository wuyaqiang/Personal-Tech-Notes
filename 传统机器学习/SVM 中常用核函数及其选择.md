一、常用核函数：

线性核（Linear核）
多项式核 （Polynomial核）
高斯核（RBF核 / 径向基核）

二、核函数的选择：（以下观点来自吴恩达）

如果 Feature 的数量很大，跟样本数量差不多，这时候选用 LR 或者是 Linear Kernel 的 SVM
如果 Feature 的数量比较小，样本数量一般，不算大也不算小，选用 SVM+Gaussian Kernel
如果 Feature 的数量比较小，而样本数量很多，需要手工添加一些 feature 变成第一种情况

即：

如果特征维数很高，往往线性可分（SVM 解决非线性分类问题的思路就是将样本映射到更高维的特征空间中），可以采用 LR 或者线性核的 SVM；
如果样本数量很多，由于求解最优化问题的时候，目标函数涉及两两样本计算内积，使用高斯核明显计算量会大于线性核，所以手动添加一些特征，使得线性可分，然后可以用 LR 或者线性核的 SVM；
如果不满足上述两点，即特征维数少，样本数量正常，可以使用高斯核的 SVM。
