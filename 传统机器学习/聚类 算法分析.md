## 1. K-Means 算法
算法流程：
1. 随机选取 k 个数据点作为初始聚类中心
2. 计算每个数据点与各个聚类中心的距离，讲每个数据点重新分配给距离它最近的聚类中心
3. 所有数据点分配完毕后，重新计算每个簇的聚类中心
4. 重复上面 2,3 两步，直到达到终止条件

终止条件：
* 没有（或最小数目）数据点被重新分配给其他聚类中心
* 没有（或最小数目）聚类中心再发生变化
* 误差平方和（SSE）局部最小

优势：
算法简洁，效率高，时间复杂度为相对于数据点数目的线性复杂度。
劣势：
只能应用于均值能够被定义的数据集上，不适用于类别型数据
需要人工事先指定聚类数目K
算法对异常值很敏感
算法对初始种子很敏感
不适用于发现那些形状不是超维椭圆体（或超维球体）的聚类

## 2. K-Means 和 EM 算法的联系
区别：
K-Means 是一种硬聚类，将每个数据点分配给一个类别
EM 是一种软聚类，得到每个数据点属于不同类别的概率
联系：
k-means 是两个步骤交替进行，可以分别看成 E 步和 M 步； 
E 步中将每个点分给中心距它最近的类（硬分配），可以看成是 EM 算法中 E 步（软分配）的近似；
M 步中将每类的中心更新为分给该类各点的均值，可以认为是在「各类分布均为单位方差的高斯分布」的假设下，最大化似然值。

## 3. 层次聚类算法


## 4. 聚类效果评价指标
首先，聚类没有统一的评价指标，不同聚类算法的目标函数相差很大，所以聚类效果的好坏需要结合具体问题进行评价。

具体应用中，可以考虑以下方法：
* 根据任务进行人工专家评估；
* 如果已知数据的类别信息，可以根据不同簇中数据的熵、纯度、查准率、查全率、F1值来度量；
* 聚类内部紧密度，即数据点和聚类中心的相似度；
* 聚类间分离度，即不同的聚类中心之间的差异度；
* 间接评估方法，聚类操作在一些任务中并不是主要任务，而是起辅助作用，所以可以通过主要任务的效果来间接评估聚类的效果好坏，对主要任务效果有提升，聚的就好些。
