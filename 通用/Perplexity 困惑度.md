困惑度用来衡量语言模型好坏的指标。

主要是根据每个词来估计一句话出现的概率，并用句子长度作 normalize。

![](https://img-blog.csdn.net/20171224134258243)

S 代表 sentence，N 是句子长度，p (wi) 是第 i 个词的概率。第一个词就是 p (w1|w0)，而 w0 是 START，表示句子的起始，是个占位符。  
PPL 越小，p (wi) 则越大，一句我们期望的 sentence 出现的概率就越高。

Perplexity 还可以认为是 average branch factor（平均分支系数），即预测下一个词时可以有多少种选择。别人在作报告时说模型的 PPL 下降到 90，可以直观地理解为，在模型生成一句话时下一个词有 90 个合理选择，可选词数越少，我们大致认为模型越准确。这样也能解释，为什么 PPL 越小，模型越好。

* 训练数据集越大，PPL 会下降得更低，1billion dataset 和 10 万 dataset 训练效果是很不一样的。
* 数据中的标点会对模型的 PPL 产生很大影响，一个句号能让 PPL 波动几十，标点的预测总是不稳定。
* 预测语句中的 “的，了” 等词也对 PPL 有很大影响，可能 “我借你的书” 比 “我借你书” 的指标值小几十，但从语义上分析有没有这些停用词并不能完全代表句子生成的好坏。

因此，语言模型评估时我们可以用 perplexity 大致估计训练效果，作出判断和分析，但它不是完全意义上的标准，具体问题还是要具体分析。
